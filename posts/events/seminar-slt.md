# Singular Learning Theory

Singularities are knowledge. This is a seminar on [Sumio Watanabe](http://watanabe-www.math.dis.titech.ac.jp/users/swatanab/)'s Singular Learning Theory. For articles that augment and complete this seminar series see [Probably Singular](https://edmundlth.github.io/posts/singular-learning-theory-part-1/). Thursdays `10:00am-12:00pm AEDT`.

* **Co-organisers**: Edmund Lau and Dan Murfet.
* **Venue**: the [Rising Sea](https://www.roblox.com/games/8165217582/The-Rising-Sea).

![banner](seminar-slt.png)

*Image from Sumio Watanabe's [homepage](http://watanabe-www.math.dis.titech.ac.jp/users/swatanab/)*.

## Schedule

Each week there is a main session and a supplementary session. Dates are AEDT.

* **13-1-22** (*Dan Murfet*): What is learning? Singularities and pendulums ([video](https://youtu.be/QZG40ZY5TeU)).
    * **Supplementary** (*Edmund Lau*): The Fisher information matrix ([video](https://youtu.be/yniLt7ONj28)).
* **20-1-22** (*Edmund Lau*):  Fisher information, KL-divergence and singular models ([video](https://youtu.be/U9bnkWuFSSM)).
    * **Supplementary** (*Liam Carroll*): Markov Chain Monte Carlo ([video](https://youtu.be/Ns4w0vtWt4A)).
* **27-1-22** (*Liam Carroll*): Neural networks and the Bayesian posterior ([video](https://youtu.be/1Esk7G3g5X8))
    * **Supplementary** (*Spencer Wong*): Rings, ideals and the Hilbert basis theorem ([video](https://youtu.be/g1tXe9Yrij8)).
* **3-2-22** (*Spencer Wong*): From analytic to algebraic I ([video](https://youtu.be/5Gkzg-zTwv4)).
    * **Supplementary** (*Ken Chan*): Resolution of singularities ([video](https://youtu.be/ssU8VZ50Wd8)).
* **10-2-22** (*Dan Murfet*): Introduction to density of states ([video](https://youtu.be/HXCpQWZfWIw), [notes](http://www.therisingsea.org/notes/metauni/slt12.pdf)).
    * **Supplementary** (*Spencer Wong*): Polynomial division and Grobner bases.
                
Coming up:

* **17-2-22** (*Spencer Wong*): From analytic to algebraic II.
    * **Supplementary** (*Dan Murfet*): Fisher information for regression models.

## Background reading

Some rough handwritten notes:

* [Deep Learning Theory 1](http://www.therisingsea.org/notes/metauni/dlt1.pdf): Why deep learning theory?
* [Deep Learning Theory 2](http://www.therisingsea.org/notes/metauni/dlt2.pdf): Thermodynamics of Singular Learning Theory
* [Deep Learning Theory 3](http://www.therisingsea.org/notes/metauni/dlt3.pdf): Phase transitions
* [Singular Learning Theory 4](http://www.therisingsea.org/notes/metauni/slt4.pdf): Local RLCT
* [Singular Learning Theory 5](http://www.therisingsea.org/notes/metauni/slt5.pdf): Symmetry and RLCT
* [Singular Learning Theory 6](http://www.therisingsea.org/notes/metauni/slt6.pdf): Generalisation and Power Laws
* [Singular Learning Theory 8](http://www.therisingsea.org/notes/metauni/slt8.pdf): Calculations for feedforward networks
* [Singular Learning Theory 12](http://www.therisingsea.org/notes/metauni/slt12.pdf): Density of states
* [Singular Learning Theory 13](http://www.therisingsea.org/notes/metauni/slt13.pdf): Asymptotics of the free energy
